volumes:
  KAFKA_VOL: {}
services:
# NOTE: will use kafka event stream as the source of truth
  kafka0:
    image: confluentinc/cp-kafka:latest
    hostname: kafka0
    container_name: kafka0
    volumes:
      - KAFKA_VOL:/var/lib/kafka/data
    networks:
      - cqrs-net
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,LISTENER_ONE:PLAINTEXT,LISTENER_TWO:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'LISTENER_ONE://kafka0:29092,LISTENER_TWO://host.docker.internal:9092'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka0:29093'
      KAFKA_LISTENERS: 'CONTROLLER://kafka0:29093,LISTENER_ONE://kafka0:29092,LISTENER_TWO://localhost:9092'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'LISTENER_ONE'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_LOG4J_LOGGERS: 'kafka.controller=TRACE,kafka.request.logger=WARN'
      KAFKA_TOOLS_LOG4J_LOGLEVEL: 'ERROR'

# TODO: Need to setup
# - confluentinc/cp-schema-registry
# - cp-ksqldb-server
# - cp-kafka-rest
# - cp-control-center (extra learning when have time)

networks:
  cqrs-net:
    external: true
